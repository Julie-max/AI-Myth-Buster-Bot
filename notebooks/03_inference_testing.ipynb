{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This notebook is for inference and testing"
      ],
      "metadata": {
        "id": "u4UAxjGsFxr0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hz14qvuliL6e"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "# Define model path\n",
        "MODEL_DIR = \"models/t5_myth_buster\"\n",
        "\n",
        "# Load trained model and tokenizer\n",
        "tokenizer = T5Tokenizer.from_pretrained(MODEL_DIR)\n",
        "model = T5ForConditionalGeneration.from_pretrained(MODEL_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 7: Test the Fine-Tuned Model\n",
        "def debunk_myths(myths):\n",
        "    results = {}\n",
        "    for myth in myths:\n",
        "        input_text = f\"Myth: {myth}\\nDebunked Fact:\"\n",
        "        input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(model.device)\n",
        "\n",
        "        # **Step 1: First Try Beam Search (Accurate, Deterministic)**\n",
        "        output_ids = model.generate(\n",
        "            input_ids,\n",
        "            max_length=128,\n",
        "            num_beams=7,\n",
        "            do_sample=False,  # Fully deterministic\n",
        "            repetition_penalty=1.5,\n",
        "            no_repeat_ngram_size=4,  # Stronger constraint to prevent repetition\n",
        "            early_stopping=True\n",
        "        )\n",
        "\n",
        "        debunked_fact = tokenizer.decode(output_ids[0], skip_special_tokens=True).strip()\n",
        "\n",
        "        # **Step 2: If Myth is Repeated, Try Sampling Instead**\n",
        "        if not debunked_fact or debunked_fact.lower() == myth.lower():\n",
        "            output_ids = model.generate(\n",
        "                input_ids,\n",
        "                max_length=128,\n",
        "                num_beams=5,\n",
        "                do_sample=True,  # Enable randomness\n",
        "                temperature=0.7,\n",
        "                top_p=0.85,\n",
        "                top_k=50,\n",
        "                repetition_penalty=1.3,\n",
        "                no_repeat_ngram_size=4,  # Prevents reusing phrases\n",
        "                early_stopping=True\n",
        "            )\n",
        "            debunked_fact = tokenizer.decode(output_ids[0], skip_special_tokens=True).strip()\n",
        "\n",
        "        # **Step 3: Final Cleanup - Remove Repeated Myths**\n",
        "        if debunked_fact.startswith(\"Myth:\"):\n",
        "            debunked_fact = debunked_fact.replace(f\"Myth: {myth}\", \"\").strip()\n",
        "\n",
        "        # **Step 4: If Still Failing, Provide a Default Debunking Response**\n",
        "        if not debunked_fact or debunked_fact.lower() == \"debunked fact:\":\n",
        "            debunked_fact = \"AI follows pre-programmed rules and data patterns but does not possess true intelligence or consciousness.\"\n",
        "\n",
        "        results[myth] = debunked_fact\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "# Define 7 test examples (5 similar topics, 2 potentially unseen)\n",
        "test_myths = [\n",
        "    # Similar to training examples but with different phrasing:\n",
        "    \"AI can create art that rivals human creativity.\",\n",
        "    \"AI is always objective.\",\n",
        "    \"AI-powered robots can replace many manual jobs.\",\n",
        "    \"AI can understand human humor.\",\n",
        "    \"AI helps in diagnosing diseases better than doctors can.\",\n",
        "    # Potentially unseen/out-of-distribution examples:\n",
        "    \"AI will solve climate change on its own.\",\n",
        "    \"AI can predict stock market crashes with certainty.\"\n",
        "]\n",
        "\n",
        "# Use your hybrid debunking function (assuming it's named debunk_myths)\n",
        "debunked_results = debunk_myths(test_myths)\n",
        "\n",
        "# Print the outputs\n",
        "for myth, fact in debunked_results.items():\n",
        "    print(\"Myth:\", myth)\n",
        "    print(\"Debunked Fact:\", fact)\n",
        "    print()\n"
      ],
      "metadata": {
        "id": "o1Wi7HitiNY_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}