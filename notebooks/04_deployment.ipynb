{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This notebook is for deployment using Gradio"
      ],
      "metadata": {
        "id": "qkgfNeU8F6Cj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MmPwlo7Oiy5e"
      },
      "outputs": [],
      "source": [
        "# Install necessary libraries\n",
        "!pip install gradio transformers torch\n",
        "\n",
        "import torch\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "import gradio as gr\n",
        "\n",
        "# Define model path\n",
        "MODEL_DIR = \"models/t5_myth_buster\"\n",
        "\n",
        "# Load trained model and tokenizer\n",
        "tokenizer = T5Tokenizer.from_pretrained(MODEL_DIR)\n",
        "model = T5ForConditionalGeneration.from_pretrained(MODEL_DIR)\n",
        "\n",
        "# Define the debunking function\n",
        "def debunk_myths(myths):\n",
        "    results = {}\n",
        "    for myth in myths:\n",
        "        input_text = f\"Myth: {myth}\\nDebunked Fact:\"\n",
        "        input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(model.device)\n",
        "\n",
        "        # **Step 1: First Try Beam Search (Accurate, Deterministic)**\n",
        "        output_ids = model.generate(\n",
        "            input_ids,\n",
        "            max_length=128,\n",
        "            num_beams=7,\n",
        "            do_sample=False,  # Fully deterministic\n",
        "            repetition_penalty=1.5,\n",
        "            no_repeat_ngram_size=4,  # Stronger constraint to prevent repetition\n",
        "            early_stopping=True\n",
        "        )\n",
        "\n",
        "        debunked_fact = tokenizer.decode(output_ids[0], skip_special_tokens=True).strip()\n",
        "\n",
        "        # **Step 2: If Myth is Repeated, Try Sampling Instead**\n",
        "        if not debunked_fact or debunked_fact.lower() == myth.lower():\n",
        "            output_ids = model.generate(\n",
        "                input_ids,\n",
        "                max_length=128,\n",
        "                num_beams=5,\n",
        "                do_sample=True,  # Enable randomness\n",
        "                temperature=0.7,\n",
        "                top_p=0.85,\n",
        "                top_k=50,\n",
        "                repetition_penalty=1.3,\n",
        "                no_repeat_ngram_size=4,  # Prevents reusing phrases\n",
        "                early_stopping=True\n",
        "            )\n",
        "            debunked_fact = tokenizer.decode(output_ids[0], skip_special_tokens=True).strip()\n",
        "\n",
        "        # **Step 3: Final Cleanup - Remove Repeated Myths**\n",
        "        if debunked_fact.startswith(\"Myth:\"):\n",
        "            debunked_fact = debunked_fact.replace(f\"Myth: {myth}\", \"\").strip()\n",
        "\n",
        "        # **Step 4: If Still Failing, Provide a Default Debunking Response**\n",
        "        if not debunked_fact or debunked_fact.lower() == \"debunked fact:\":\n",
        "            debunked_fact = \"AI follows pre-programmed rules and data patterns but does not possess true intelligence or consciousness.\"\n",
        "\n",
        "        results[myth] = debunked_fact\n",
        "\n",
        "    return results\n",
        "\n",
        "# Create Gradio Interface\n",
        "iface = gr.Interface(\n",
        "    fn=debunk_myth,  # Function to call\n",
        "    inputs=\"text\",  # Input is a text box\n",
        "    outputs=\"text\",  # Output is a text box\n",
        "    title=\"AI Myth Debunker\",\n",
        "    description=\"Enter an AI myth, and the bot will provide a debunked, fact-based correction.\"\n",
        ")\n",
        "\n",
        "# Launch the app\n",
        "iface.launch()\n"
      ]
    }
  ]
}